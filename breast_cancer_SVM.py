# -*- coding: utf-8 -*-
"""Hyeri_Kim_SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S5-fnAGOeQRnCwvVBkKVEucCKh38muZt

# SVM Assignment

#### Author : Hyeri Kim
#### Stu ID : 301208760
#### Course : COMP247
#### Section : 003
#### Professor : Merlin James Rukshan Dennis

### Exercise **1**

#### Load & check the data

1.	Load the data into a pandas dataframe named data_firstname_df2 where first name is you name.

2.	Carryout some initial investigations:

  a.	Check the names and types of columns.

  b.	Check the missing values.

  c.	Check the statistics of the numeric fields (mean, min, max, median, count..etc.)

  d.	In you written response write a paragraph explaining your findings about each column.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report

data_hyeri = pd.read_csv('breast_cancer.csv')

data_hyeri.info()

data_hyeri.head(10)

data_hyeri.isnull().sum()

data_hyeri.describe()

"""#### Pre-process and visualize the data

3.	Replace the ‘?’ mark in the ‘bare’ column by np.nan and change the type to ‘float’
4.	Fill any missing data with the median of the column.
5.	Drop the ID column
6.	Using Pandas, Matplotlib, seaborn (you can use any or a mix) generate 3-5 plots and add them to your written response explaining what are the key insights and findings from the plots.
7.	Separate the features from the class.
8.	Split your data into train 80% train and 20% test, use the last two digits of your student number for the seed.
"""

data_hyeri.bare.replace('?', np.nan, inplace=True)

data_hyeri.bare.astype('float')

data_hyeri.fillna(data_hyeri.bare.median(), inplace=True)

data_hyeri.drop('ID', axis=1, inplace=True)

#sns.pairplot(data_hyeri, hue='class', kind='kde')
#plt.show()

# Dimensionality reduction
pca = PCA(1)
size_shape = pca.fit_transform(data_hyeri[['size', 'shape']])   # Since they are highly correlated with each other, combine them into a single feature

print('Explained variance ratio: %f' % pca.explained_variance_ratio_[0])

data_hyeri.insert(1, 'size_shape', size_shape)
data_hyeri.drop(['size', 'shape'], axis=1, inplace=True)

cols = ['size_shape', 'thickness', 'Marg', 'Epith', 'nucleoli']
X = data_hyeri[cols]
y = data_hyeri['class'].replace([2, 4], [0, 1]).astype('category')

# Class column is replaced with binary values of 0 and 1
# 0 : benign tumor
# 1 : malignant tumor

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=60)

"""#### Build Classification Models
Support vector machine classifier with linear kernel

9.	Train an SVM classifier using the training data, set the kernel to linear and set the regularization parameter to C= 0.1. Name the classifier clf_linear_firstname.
10.	Print out two accuracy score one for the model on the training set i.e. X_train, y_train and the other on the testing set i.e. X_test, y_test. Record both results in your written response.
11.	Generate the accuracy matrix. Record the results in your written response.
Support vector machine classifier with “rbf” kernel
12.	Repeat steps 9 to 11, in step 9 change the kernel to “rbf” and do not set any value for C.
Support vector machine classifier with “poly” kernel

13.	Repeat steps 9 to 11, in step 9 change the kernel to “poly” and do not set any value for C.
Support vector machine classifier with “sigmoid” kernel
14.	Repeat steps 9 to 11, in step 9 change the kernel to “sigmoid” and do not set any value for C.

(Optional: for steps 9 to 14 you can consider a loop)
"""

for C, kernel in[(0.1, 'linear'), (1, 'rbf'), (1, 'poly'), (1, 'sigmoid')]:
  svm_clf_hyeri = SVC(C=C, kernel=kernel)
  svm_clf_hyeri.fit(X_train, y_train)

  pred_y_train = svm_clf_hyeri.predict(X_train)
  print('Metric on training set for %s\n' % kernel, classification_report(y_train, pred_y_train))

  pred_y_test = svm_clf_hyeri.predict(X_test)
  print('Metric on test set for %s\n' % kernel, classification_report(y_test, pred_y_test))
  print('-'*60)

"""### Exercise **2**

1.	Load the data into a pandas dataframe named data_firstname_df2 where first name is you name.
2.	Replace the ‘?’ mark in the ‘bare’ column by np.nan and change the type to ‘float’
3.	Drop the ID column
4.	Separate the features from the class.
5.	Split your data into train 80% train and 20% test   use the last two digits of your student number for the seed.
"""

import pandas as pd
import numpy as np
from joblib import dump
from sklearn.impute import SimpleImputer
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

data_hyeri_df2 = pd.read_csv('breast_cancer.csv')

data_hyeri_df2.replace('?', np.nan, inplace=True)
data_hyeri_df2.bare.astype('float')
data_hyeri_df2.drop('ID', axis=1, inplace=True)

pca = PCA(1)
size_shape = pca.fit_transform(data_hyeri_df2[['size', 'shape']])
print('Explained ratio: %f' % pca.explained_variance_ratio_[0])

data_hyeri_df2.insert(1, 'size_shape', size_shape)
data_hyeri_df2.drop(['size', 'shape'], axis=1, inplace=True)

cols = ['size_shape', 'thickness', 'Marg', 'Epith', 'nucleoli']
X = data_hyeri_df2[cols]
y = data_hyeri_df2['class'].replace([2, 4], [0, 1]).astype('category')

# Class column is replaced with binary values of 0 and 1
# 0 : benign tumor
# 1 : malignant tumor

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=60)

"""6.	Using the preprocessing library to define two transformer objects to transform your training data:

  a.	Fill the missing values with the median (hint: checkout SimpleImputer)
  
  b.	Scale the data  (hint: checkout StandardScaler)

"""

imputer = SimpleImputer(strategy='median')
X_train_imputed = imputer.fit_transform(X_train)

scaler = StandardScaler()
X_train_preprocessed = scaler.fit_transform(X_train_imputed)

"""7.	Combine the two transformers into a pipeline name it num_pipe_firstname."""

num_pipe_hyeri = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

x_train_preprocessed = num_pipe_hyeri.fit_transform(X_train)

"""8.	Create a new Pipeline that has two steps the first is the num_pipe_firstname and the second is an SVM classifier with random state = last two digits of your student number. Name the pipeline pipe_svm_firstname. (make note of the labels)"""

svc = SVC(random_state=60)

# Create the pipeline that combines the preprocessing steps with the classifier

pipe_svm_hyeri = Pipeline([
    ('preprocessing', num_pipe_hyeri),
    ('svm', svc)
])

pipe_svm_hyeri.fit(X_train, y_train)

y_pred = pipe_svm_hyeri.predict(X_test)

print(classification_report(y_test, y_pred))

"""10.	Define the grid search parameters in an object and name it param_grid, as follows:

  a.	        'svc__kernel': ['linear', 'rbf','poly'],

  b.	        'svc__C':  [0.01,0.1, 1, 10, 100],

  c.	         'svc__gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0],

  d.	         'svc__degree':[2,3]},

  Make sure you replace svc with the label you used in the pipe_svm_firstname for the model

"""

param_grid = {'svm__kernel': ['linear', 'rbf', 'poly'],
              'svm__C': [0.01, 0.1, 1, 10, 100],
              'svm__gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0],
              'svm__degree': [2, 3]}

"""12.	Create a grid search object name it grid_search_firstname with the following parameters:

  a.	estimator= pipe_svm_firstname

  b.	param_grid=param_grid_svm

  c.	scoring='accuracy'

  d.	refit = True
  
  e.	verbose = 3

"""

grid_search_hyeri = GridSearchCV(pipe_svm_hyeri, param_grid, scoring='accuracy', refit=True, verbose=3)

grid_search_hyeri.fit(X_train, y_train)

"""15.	Print out the best parameters and note it in your written response
16.	Printout the best estimator and note it in your written response

"""

print('best parameter set:', grid_search_hyeri.best_params_)
print('best estimator:\n')
print(grid_search_hyeri.best_estimator_)

"""17.	Fit the test data the grid search object and note it in your written response
18.	Printout the accuracy score and note it in your written response.

"""

y_pred = grid_search_hyeri.predict(X_test)

print('Metric on test set\n', classification_report(y_test, y_pred))

"""19.	Create an object that holds the best model i.e. best estimator to an object named best_model_firstname
20.	Save the model using the joblib  (dump).
21.	Save the full pipeline using the joblib – (dump).

"""

best_model_hyeri = grid_search_hyeri.best_estimator_

dump(best_model_hyeri, 'best_model_hyeri.joblib')

dump(best_model_hyeri, 'full_pipeline_hyeri.joblib')